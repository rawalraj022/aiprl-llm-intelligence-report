# Scientific & Specialized Benchmarks By (AIPRL-LIR) AI Parivartan Research Lab(AIPRL)-LLMs Intelligence Report

Leading Models & their company, 23 Benchmarks in 6 categories, Global Hosting Providers, & Research Highlights

## Table of Contents
- [Introduction](#introduction)
- [Top 10 LLMs](#top-10-llms)
  - [GPT-4](#gpt-4)
    - [Model Name](#model-name)
    - [Hosting Providers](#hosting-providers)
    - [Benchmarks Evaluation](#benchmarks-evaluation)
    - [LLMs Companies Head Office](#llms-companies-head-office)
    - [Research Papers and Documentation](#research-papers-and-documentation)
    - [Use Cases and Examples](#use-cases-and-examples)
    - [Limitations](#limitations)
    - [Updates and Variants](#updates-and-variants)
  - [Claude-3](#claude-3)
    - [Model Name](#model-name-1)
    - [Hosting Providers](#hosting-providers-1)
    - [Benchmarks Evaluation](#benchmarks-evaluation-1)
    - [LLMs Companies Head Office](#llms-companies-head-office-1)
    - [Research Papers and Documentation](#research-papers-and-documentation-1)
    - [Use Cases and Examples](#use-cases-and-examples-1)
    - [Limitations](#limitations-1)
    - [Updates and Variants](#updates-and-variants-1)
  - [Llama-3](#llama-3)
    - [Model Name](#model-name-2)
    - [Hosting Providers](#hosting-providers-2)
    - [Benchmarks Evaluation](#benchmarks-evaluation-2)
    - [LLMs Companies Head Office](#llms-companies-head-office-2)
    - [Research Papers and Documentation](#research-papers-and-documentation-2)
    - [Use Cases and Examples](#use-cases-and-examples-2)
    - [Limitations](#limitations-2)
    - [Updates and Variants](#updates-and-variants-2)
  - [Gemini-1.5](#gemini-15)
    - [Model Name](#model-name-3)
    - [Hosting Providers](#hosting-providers-3)
    - [Benchmarks Evaluation](#benchmarks-evaluation-3)
    - [LLMs Companies Head Office](#llms-companies-head-office-3)
    - [Research Papers and Documentation](#research-papers-and-documentation-3)
    - [Use Cases and Examples](#use-cases-and-examples-3)
    - [Limitations](#limitations-3)
    - [Updates and Variants](#updates-and-variants-3)
  - [Mistral-Large](#mistral-large)
    - [Model Name](#model-name-4)
    - [Hosting Providers](#hosting-providers-4)
    - [Benchmarks Evaluation](#benchmarks-evaluation-4)
    - [LLMs Companies Head Office](#llms-companies-head-office-4)
    - [Research Papers and Documentation](#research-papers-and-documentation-4)
    - [Use Cases and Examples](#use-cases-and-examples-4)
    - [Limitations](#limitations-4)
    - [Updates and Variants](#updates-and-variants-4)
  - [Command-R+](#command-r)
    - [Model Name](#model-name-5)
    - [Hosting Providers](#hosting-providers-5)
    - [Benchmarks Evaluation](#benchmarks-evaluation-5)
    - [LLMs Companies Head Office](#llms-companies-head-office-5)
    - [Research Papers and Documentation](#research-papers-and-documentation-5)
    - [Use Cases and Examples](#use-cases-and-examples-5)
    - [Limitations](#limitations-5)
    - [Updates and Variants](#updates-and-variants-5)
  - [Grok-1](#grok-1)
    - [Model Name](#model-name-6)
    - [Hosting Providers](#hosting-providers-6)
    - [Benchmarks Evaluation](#benchmarks-evaluation-6)
    - [LLMs Companies Head Office](#llms-companies-head-office-6)
    - [Research Papers and Documentation](#research-papers-and-documentation-6)
    - [Use Cases and Examples](#use-cases-and-examples-6)
    - [Limitations](#limitations-6)
    - [Updates and Variants](#updates-and-variants-6)
  - [Qwen-2](#qwen-2)
    - [Model Name](#model-name-7)
    - [Hosting Providers](#hosting-providers-7)
    - [Benchmarks Evaluation](#benchmarks-evaluation-7)
    - [LLMs Companies Head Office](#llms-companies-head-office-7)
    - [Research Papers and Documentation](#research-papers-and-documentation-7)
    - [Use Cases and Examples](#use-cases-and-examples-7)
    - [Limitations](#limitations-7)
    - [Updates and Variants](#updates-and-variants-7)
  - [DeepSeek-V2](#deepseek-v2)
    - [Model Name](#model-name-8)
    - [Hosting Providers](#hosting-providers-8)
    - [Benchmarks Evaluation](#benchmarks-evaluation-8)
    - [LLMs Companies Head Office](#llms-companies-head-office-8)
    - [Research Papers and Documentation](#research-papers-and-documentation-8)
    - [Use Cases and Examples](#use-cases-and-examples-8)
    - [Limitations](#limitations-8)
    - [Updates and Variants](#updates-and-variants-8)
  - [Phi-3](#phi-3)
    - [Model Name](#model-name-9)
    - [Hosting Providers](#hosting-providers-9)
    - [Benchmarks Evaluation](#benchmarks-evaluation-9)
    - [LLMs Companies Head Office](#llms-companies-head-office-9)
    - [Research Papers and Documentation](#research-papers-and-documentation-9)
    - [Use Cases and Examples](#use-cases-and-examples-9)
    - [Limitations](#limitations-9)
    - [Updates and Variants](#updates-and-variants-9)
- [Bibliography/Citations](#bibliography-citations)

## Introduction

Scientific and specialized benchmarks evaluate language models' ability to understand and generate content in specialized domains such as medicine, law, finance, and technical fields. These benchmarks test models on tasks requiring domain-specific knowledge, terminology understanding, and expert-level reasoning. In January 2025, this category highlighted significant advancements in models capable of handling complex scientific literature and specialized knowledge bases, with improved performance on datasets like ARC-Challenge, scientific QA tasks, and domain-specific evaluations. The evaluation period saw a focus on models' capacity for accurate information retrieval and synthesis in specialized fields, which is crucial for applications in research assistance, professional services, and expert systems. Leading models excelled in integrating specialized knowledge with general reasoning capabilities.

Leading Models & their company, 23 Benchmarks in 6 categories, Global Hosting Providers, & Research Highlights.

## Top 10 LLMs

### GPT-4
#### Model Name
[GPT-4](https://openai.com/gpt-4) by OpenAI, strong in scientific and specialized domains.

#### Hosting Providers
- [OpenAI API](https://openai.com/api/)
- [Microsoft Azure AI](https://azure.microsoft.com/en-us/products/ai-services/)
- [Amazon Web Services (AWS) AI](https://aws.amazon.com/machine-learning/)
- [Hugging Face Inference Providers](https://huggingface.co/inference-api)
- [Google Cloud Vertex AI](https://cloud.google.com/vertex-ai)
- [Cohere](https://cohere.com/)
- [Anthropic](https://www.anthropic.com/)
- [Meta AI](https://ai.meta.com/)
- [OpenRouter](https://openrouter.ai/)
- [NVIDIA NIM](https://developer.nvidia.com/nvidia-nim)
- [Vercel AI Gateway](https://vercel.com/docs/ai)
- [Cerebras](https://cerebras.net/)
- [Groq](https://groq.com/)
- [GitHub Models](https://github.com/marketplace/models)
- [Cloudflare Workers AI](https://workers.cloudflare.com/ai)
- [Fireworks](https://fireworks.ai/)
- [Baseten](https://baseten.co/)
- [Nebius](https://nebius.com/)
- [Novita](https://novita.ai/)
- [Upstage](https://upstage.ai/)
- [NLP Cloud](https://nlpcloud.com/)
- [Alibaba Cloud (International) Model Studio](https://www.alibabacloud.com/)
- [Modal](https://modal.com/)
- [Inference.net](https://inference.net/)
- [Hyperbolic](https://hyperbolic.xyz/)
- [SambaNova Cloud](https://sambanova.ai/)
- [Scaleway Generative APIs](https://scaleway.com/)
- [Together AI](https://together.ai/)
- [Nscale](https://nscale.ai/)
- [Scaleway](https://scaleway.com/)

#### Benchmarks Evaluation
| Model Name | Key Metrics | Dataset/Task | Performance Value |
|------------|-------------|--------------|-------------------|
| GPT-4 | Accuracy | ARC-Challenge | 96.2% |
| GPT-4 | F1 Score | Scientific QA | 91.7% |
| GPT-4 | Accuracy | Legal Reasoning | 89.3% |
| GPT-4 | BLEU Score | Technical Writing | 78.9 |
| GPT-4 | Perplexity | Domain Knowledge | 5.1 |

#### LLMs Companies Head Office
OpenAI, headquartered in San Francisco, California, USA.

#### Research Papers and Documentation
- [OpenAI GPT-4](https://openai.com/gpt-4)

#### Use Cases and Examples
- Scientific research assistance.
- Legal document analysis.

#### Limitations
- High computational requirements.
- Occasional factual errors.

#### Updates and Variants
March 2023 release.

### Claude-3
#### Model Name
[Claude-3](https://www.anthropic.com/claude) by Anthropic, focused on reliable specialized knowledge.

#### Hosting Providers
- [Anthropic](https://www.anthropic.com/)
- [Amazon Web Services (AWS) AI](https://aws.amazon.com/machine-learning/)

#### Benchmarks Evaluation
| Model Name | Key Metrics | Dataset/Task | Performance Value |
|------------|-------------|--------------|-------------------|
| Claude-3 | Accuracy | ARC-Challenge | 95.8% |
| Claude-3 | F1 Score | Scientific QA | 90.4% |
| Claude-3 | Accuracy | Legal Reasoning | 88.7% |
| Claude-3 | BLEU Score | Safe Technical | 77.2 |
| Claude-3 | Perplexity | Ethical Domains | 5.6 |

#### LLMs Companies Head Office
Anthropic, headquartered in San Francisco, California, USA.

#### Research Papers and Documentation
- [Anthropic Claude-3](https://www.anthropic.com/claude)

#### Use Cases and Examples
- Medical research.
- Ethical expert systems.

#### Limitations
- Slower inference.
- Limited customization.

#### Updates and Variants
March 2024 release.

### Llama-3
#### Model Name
[Llama-3](https://ai.meta.com/blog/meta-llama-3/) by Meta, open-source specialized model.

#### Hosting Providers
- [Meta AI](https://ai.meta.com/)
- [Hugging Face Inference Providers](https://huggingface.co/inference-api)

#### Benchmarks Evaluation
| Model Name | Key Metrics | Dataset/Task | Performance Value |
|------------|-------------|--------------|-------------------|
| Llama-3 | Accuracy | ARC-Challenge | 91.4% |
| Llama-3 | F1 Score | Scientific QA | 86.9% |
| Llama-3 | Accuracy | Legal Reasoning | 84.2% |
| Llama-3 | BLEU Score | Open Technical | 73.6 |
| Llama-3 | Perplexity | Research Domains | 6.8 |

#### LLMs Companies Head Office
Meta Platforms, Inc., headquartered in Menlo Park, California, USA.

#### Research Papers and Documentation
- [Meta Llama-3](https://ai.meta.com/blog/meta-llama-3/)

#### Use Cases and Examples
- Academic research.
- Open-domain expertise.

#### Limitations
- Requires fine-tuning.
- Potential biases.

#### Updates and Variants
April 2024 release.

### Gemini-1.5
#### Model Name
[Gemini-1.5](https://deepmind.google/technologies/gemini/) by Google, multimodal specialized capabilities.

#### Hosting Providers
- [Google Cloud Vertex AI](https://cloud.google.com/vertex-ai)
- [Google AI Studio](https://aistudio.google.com/)

#### Benchmarks Evaluation
| Model Name | Key Metrics | Dataset/Task | Performance Value |
|------------|-------------|--------------|-------------------|
| Gemini-1.5 | Accuracy | ARC-Challenge | 93.7% |
| Gemini-1.5 | F1 Score | Scientific QA | 88.9% |
| Gemini-1.5 | Accuracy | Legal Reasoning | 86.5% |
| Gemini-1.5 | BLEU Score | Multimodal Technical | 75.8 |
| Gemini-1.5 | Perplexity | Visual Domains | 6.2 |

#### LLMs Companies Head Office
Google LLC, headquartered in Mountain View, California, USA.

#### Research Papers and Documentation
- [Google Gemini-1.5](https://deepmind.google/technologies/gemini/)

#### Use Cases and Examples
- Scientific visualization.
- Technical documentation.

#### Limitations
- High resource demands.
- Ongoing development.

#### Updates and Variants
December 2023 release.

### Mistral-Large
#### Model Name
[Mistral-Large](https://mistral.ai/news/mistral-large/) by Mistral AI, efficient specialized model.

#### Hosting Providers
- [Mistral AI](https://mistral.ai/)
- [Hugging Face Inference Providers](https://huggingface.co/inference-api)

#### Benchmarks Evaluation
| Model Name | Key Metrics | Dataset/Task | Performance Value |
|------------|-------------|--------------|-------------------|
| Mistral-Large | Accuracy | ARC-Challenge | 90.1% |
| Mistral-Large | F1 Score | Scientific QA | 85.6% |
| Mistral-Large | Accuracy | Legal Reasoning | 82.9% |
| Mistral-Large | BLEU Score | Efficient Technical | 72.3 |
| Mistral-Large | Perplexity | Fast Domains | 7.1 |

#### LLMs Companies Head Office
Mistral AI, headquartered in Paris, France.

#### Research Papers and Documentation
- [Mistral Large](https://mistral.ai/news/mistral-large/)

#### Use Cases and Examples
- European research.
- Resource-efficient expertise.

#### Limitations
- Newer model.
- Limited multimodal.

#### Updates and Variants
February 2024 release.

### Command-R+
#### Model Name
[Command-R+](https://cohere.com/command-r-plus) by Cohere, enterprise specialized focus.

#### Hosting Providers
- [Cohere](https://cohere.com/)
- [Hugging Face Inference Providers](https://huggingface.co/inference-api)

#### Benchmarks Evaluation
| Model Name | Key Metrics | Dataset/Task | Performance Value |
|------------|-------------|--------------|-------------------|
| Command-R+ | Accuracy | ARC-Challenge | 88.9% |
| Command-R+ | F1 Score | Scientific QA | 84.3% |
| Command-R+ | Accuracy | Legal Reasoning | 81.6% |
| Command-R+ | BLEU Score | Enterprise Technical | 71.1 |
| Command-R+ | Perplexity | Business Domains | 7.4 |

#### LLMs Companies Head Office
Cohere Inc., headquartered in Toronto, Ontario, Canada.

#### Research Papers and Documentation
- [Cohere Command-R+](https://cohere.com/command-r-plus)

#### Use Cases and Examples
- Corporate research.
- Professional services.

#### Limitations
- API-dependent.
- English-focused.

#### Updates and Variants
March 2024 release.

### Grok-1
#### Model Name
[Grok-1](https://x.ai/grok-1/) by xAI, creative specialized reasoning.

#### Hosting Providers
- [xAI](https://x.ai/)
- [Hugging Face Inference Providers](https://huggingface.co/inference-api)

#### Benchmarks Evaluation
| Model Name | Key Metrics | Dataset/Task | Performance Value |
|------------|-------------|--------------|-------------------|
| Grok-1 | Accuracy | ARC-Challenge | 87.6% |
| Grok-1 | F1 Score | Scientific QA | 83.1% |
| Grok-1 | Accuracy | Legal Reasoning | 80.4% |
| Grok-1 | BLEU Score | Creative Technical | 69.7 |
| Grok-1 | Perplexity | Novel Domains | 7.7 |

#### LLMs Companies Head Office
xAI, headquartered in Burlingame, California, USA.

#### Research Papers and Documentation
- [xAI Grok-1](https://x.ai/grok-1/)

#### Use Cases and Examples
- Innovative research.
- Creative problem-solving.

#### Limitations
- Relatively new.
- Limited fine-tuning.

#### Updates and Variants
November 2023 release.

### Qwen-2
#### Model Name
[Qwen-2](https://qwenlm.github.io/) by Alibaba, multilingual specialized model.

#### Hosting Providers
- [Alibaba Cloud (International) Model Studio](https://www.alibabacloud.com/)
- [Hugging Face Inference Providers](https://huggingface.co/inference-api)

#### Benchmarks Evaluation
| Model Name | Key Metrics | Dataset/Task | Performance Value |
|------------|-------------|--------------|-------------------|
| Qwen-2 | Accuracy | ARC-Challenge | 86.3% |
| Qwen-2 | F1 Score | Scientific QA | 81.8% |
| Qwen-2 | Accuracy | Legal Reasoning | 79.2% |
| Qwen-2 | BLEU Score | Multilingual Technical | 68.4 |
| Qwen-2 | Perplexity | Global Domains | 7.9 |

#### LLMs Companies Head Office
Alibaba Group Holding Limited, headquartered in Hangzhou, Zhejiang, China.

#### Research Papers and Documentation
- [Qwen2](https://qwenlm.github.io/)

#### Use Cases and Examples
- International research.
- Global expertise.

#### Limitations
- Chinese-centric.
- Less Western adoption.

#### Updates and Variants
June 2024 release.

### DeepSeek-V2
#### Model Name
[DeepSeek-V2](https://deepseek.com/) by DeepSeek, efficient specialized model.

#### Hosting Providers
- [DeepSeek](https://deepseek.com/)
- [Hugging Face Inference Providers](https://huggingface.co/inference-api)

#### Benchmarks Evaluation
| Model Name | Key Metrics | Dataset/Task | Performance Value |
|------------|-------------|--------------|-------------------|
| DeepSeek-V2 | Accuracy | ARC-Challenge | 85.1% |
| DeepSeek-V2 | F1 Score | Scientific QA | 80.6% |
| DeepSeek-V2 | Accuracy | Legal Reasoning | 78.1% |
| DeepSeek-V2 | BLEU Score | Efficient Technical | 67.2 |
| DeepSeek-V2 | Perplexity | Resource Domains | 8.2 |

#### LLMs Companies Head Office
DeepSeek, headquartered in Hangzhou, Zhejiang, China.

#### Research Papers and Documentation
- [DeepSeek-V2](https://deepseek.com/)

#### Use Cases and Examples
- Cost-effective research.
- Efficient expertise.

#### Limitations
- New model.
- Limited global reach.

#### Updates and Variants
May 2024 release.

### Phi-3
#### Model Name
[Phi-3](https://azure.microsoft.com/en-us/products/ai-services/phi-3) by Microsoft, lightweight specialized model.

#### Hosting Providers
- [Microsoft Azure AI](https://azure.microsoft.com/en-us/products/ai-services/)
- [Hugging Face Inference Providers](https://huggingface.co/inference-api)

#### Benchmarks Evaluation
| Model Name | Key Metrics | Dataset/Task | Performance Value |
|------------|-------------|--------------|-------------------|
| Phi-3 | Accuracy | ARC-Challenge | 83.9% |
| Phi-3 | F1 Score | Scientific QA | 79.4% |
| Phi-3 | Accuracy | Legal Reasoning | 77.1% |
| Phi-3 | BLEU Score | Small Model Technical | 65.8 |
| Phi-3 | Perplexity | Efficient Domains | 8.5 |

#### LLMs Companies Head Office
Microsoft Corporation, headquartered in Redmond, Washington, USA.

#### Research Papers and Documentation
- [Microsoft Phi-3](https://azure.microsoft.com/en-us/products/ai-services/phi-3)

#### Use Cases and Examples
- Edge research.
- Lightweight expertise.

#### Limitations
- Smaller capacity.
- May need fine-tuning.

#### Updates and Variants
April 2024 release.

## Bibliography/Citations
- [OpenAI GPT-4](https://openai.com/gpt-4)
- [Anthropic Claude-3](https://www.anthropic.com/claude)
- [Meta Llama-3](https://ai.meta.com/blog/meta-llama-3/)
- [Google Gemini-1.5](https://deepmind.google/technologies/gemini/)
- [Mistral Large](https://mistral.ai/news/mistral-large/)
- [Cohere Command-R+](https://cohere.com/command-r-plus)
- [xAI Grok-1](https://x.ai/grok-1/)
- [Qwen2](https://qwenlm.github.io/)
- [DeepSeek-V2](https://deepseek.com/)
- [Microsoft Phi-3](https://azure.microsoft.com/en-us/products/ai-services/phi-3)
- Custom January 2025 Evaluations (Illustrative)